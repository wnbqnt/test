<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Math Rendering Example</title>
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>
  <h1>Understanding LoRA Layers in Detail</h1>
  <p>In traditional fine-tuning, the weights of a neural network layer are updated directly. For a linear layer with weight matrix \( \mathbf{W}_0 \in \mathbb{R}^{d \times k} \), the output is:</p>
  <p>$$\mathbf{y} = \mathbf{W}_0 \mathbf{x}$$</p>
</body>
</html>
